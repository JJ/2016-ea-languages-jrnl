\documentclass[runningheads,a4paper]{llncs}

\usepackage{cite}
\usepackage{array}

\usepackage[utf8]{inputenc}
\usepackage{hyperref}
\usepackage{amssymb}
\usepackage{amsmath}
\setcounter{tocdepth}{3}
\usepackage{graphicx}
\usepackage{multirow}
\usepackage{rotating}
\usepackage{subfigure}

\begin{document}
%\SweaveOpts{concordance=TRUE}

<<setup, cache=FALSE,echo=FALSE>>=
library("ggplot2")
library("ggthemes")
library(RColorBrewer)
measures.bf <- read.csv('data/measures-bitflip.csv')
measures.xo <- read.csv('data/measures-xover.csv')
measures.mo <- read.csv('data/measures-maxones.csv')
ratios <- read.csv('data/ratios.csv')
ranks <- read.csv('data/ranks.csv')
@


\title{Ranking the performance of compiled and interpreted languages
  in genetic algorithms} 

\author{Juan-Julián Merelo-Guervós \and Israel
    Blancas-Álvarez \and Pedro A. Castillo \and Gustavo Romero \inst{1} 
\and
Victor M. Rivas \inst{2}
\and
Mario García-Valdez, Amaury Hernández-Águila \inst{3}
\and
Mario Román \inst{4}
}


\institute{CITIC and Computer Architecture and Technology Department\\
  University of Granada (Spain)\\
  Email: (jmerelo,iblancasa,pacv,gustavo)@ugr.es \and
Department of Computer Sciences\\
University of Jaén (Spain)\\
Email: vrivas@ujaen.es \and
Tijuana Institute of Technology (Mexico)\\
Email: {amherag,mario}@tectijuana.edu.mx \and
University of Granada (Spain)\\
Email: mromang08@correo.ugr.es }

\maketitle

\begin{abstract} 
There are many computer languages, but the evolutionary algorithm
world has mostly exploited a few popular ones, avoiding other less
popular or emerging languages, specially if they are not compiled
languages; implementation details and data structures have received
some more attention, but also limited to particular languages.
In this paper we measure the execution speed of three common operation in
genetic algorithms of many popular and
emerging computer languages using different data structures and
implementation alternatives, with two objectives: create a ranking for
these operations, compare relative speeds taking into account
different chromosome sizes and data structures and dispel or show
evidence for several hypothesis that underlie most popular
evolutionary algorithm libraries and applications. 
\end{abstract}

\begin{keywords}
Bench\-mark, implementation of evolutionary algorithms, onemax, genetic operators, programming languages.
\end{keywords}

\section{Introduction}

In the same spirit of the {\em No Free Lunch} theorem
\cite{Wolpert-1997-NFL} we could consider there is a {\em no fast
  lunch} \cite{2015arXiv151101088M}
hypothesis for the implementation of evolutionary optimization problems, in the
sense that, while there are particular languages that might be the
fastest for particular problem sizes and specially fitness functions
there is no single language that is the fastest for all chromosomosome
sizes, implementations and fitness functions. But the main problem is
that implementation decisions, and in many ocassions reviewer reports,
are based on common beliefs such as thinking that a particular
language is the fastest or other language is too slow to even being
taken in to consideration for implementing evolutionary algorithms.  

After initial tests on a smaller number of languages
\cite{DBLP:conf/evoW/MereloCBRGFRV16} and three different data
structures, in this paper we add more languages, different data
structures and also, in the case of languages with a particularly bad
result, new implementations including some made using 
released evolutionary algorithm libraries, and finally even 
found and corrected some bugs.  

To use the results we already had, we have re-used the same
operations: crossover, mutation and onemax. In general
\cite{DBLP:conf/iwann/MereloRACML11} and except in the case of
benchmarks, an EA application will not spend the majority of the time
running these functions; as there are other more demanding tasks 
like sorting or evaluating complex fitness functions.
However, these functions are well covered by several %which functions? operators or fitness? 
general purpose
benchmarks so you can usually rely on any of them for choosing a
language to implement that part of your EA. A priori, this result
would extend only to some implementations of genetic
algorithms. However, in this paper we would like to present not only
the result itself, which is interesting, but also a methodology to
first consider new languages for implementing evolutionary algorithms
for the value or insights they might give to the algorithm mechanism,
and second to take real-world measures and benchmark them to test their
speed and performance relative to other common languages instead of
choosing usual languages blindly based only on past experience. % delete blindly?  

The rest of the paper is organized as follows: coming up next in
Section \ref{sec:soa}, we will present the state of the art of the
analysis of EA implementations. Next we will present in
Section \ref{sec:exp} 
the tests we have used for this paper and its rationale along with the
languages we have chosen for carrying them out. Finally, in Section
\ref{sec:res} we 
will present the results of measuring the performance of eleven
languages running some widely used EA operators and functions 
mutation, crossover and OneMax. Finally, we will draw the conclusions
and present future lines of work.

\section{State of the art}
\label{sec:soa}

The
first published benchmarks of evolutionary algorithms \cite{jose1994genetic}
focused on implementation details using C and C++; since then, there
are not many publications on the subject, until recently when Alba et al. examined
the performance of different data structures, all of them using the
same language, in \cite{alba2007influence}. Our paper \cite{ae09}
described the implementation of an evolutionary algorithm in Perl,
also used in this paper, proving that, as a whole, Perl could run
evolutionary algorithms almost as fast as Java, but if we took
into consideration other factors like actual coding speed measured by
single lines of code, Perl was better. 

Most papers, if not all, including this one, focus on single-threaded
procedural environments; for instance, a recent paper
\cite{nesmachnow2015empirical} focuses on a single language, C++.  In
these cases {\em classical} languages have
a certain advantage. However, innovation has not only spawned new
languages but also new architectures like the Kappa architecture \cite{KappaArch}, 
microservices \cite{namiot2014micro} or
service-oriented frameworks 
\cite{garcia2010distributed,DBLP:journals/soco/Garcia-SanchezGCAG13} 
where we could envision that different parts of an evolutionary
algorithm might be written in different languages, but also in new
languages better suited for certain tasks. The {\em no fast lunch} principle
enunciated above implies that different languages could be used for
distributed systems, with the fastest or most appropriate language
used for every part of it. %If there is space we could put JavaScript 
%as an example of a language best suited for particular environment
%Also acknowledge some properties of popular langs like maturity, 
%standard libraries, trained pros etc. 

All in all, existing literature focuses either on a single language
and different data structures or different, and mainly popular,
languages with a single data structure. In our previous published
research \cite{DBLP:conf/evoW/MereloCBRGFRV16} we focused on fewer
languages and mainly tried to measure their scaling behavior across
different lengths, and we found that Java, C\# and C obtained the best
results. However, we did not attempt to create a rank or measure
relative speeds across all tests. Besides adding more languages, we do
exactly that in this paper, reproducing the results obtained there and
adding new languages.

In the next section we will explain how the experiment was set up and
the functions used for it.

\section{Experimental setup}
\label{sec:exp}

We have used bitflip mutation, crossover and count-ones or onemax this
and the previous expermiments, mainly  representativeness. In general,
they exercise only a small part of the language capabilities,
involving mainly integer and memory-access performance through
loops. However, the implementation of these operations is deceptively
simple, specially for MaxOnes, a problem frequently used in
programming job interviews. 

Loops are also a key component in performance. Most languages allow
{\tt for} loops, however, many can also perform {\em map} implicit
loops where a function is run over each component of a data structure,
reducing sequential or random access to arrays. When available, we
have used these types of functions.

This implies that
despite its simplicity, the results have wider applicability, except
for floating point performance, which is not tested, mainly because it
is a major component of many fitness functions, not so much of the
evolutionary algorithm itself. 

Chromosomes in EAs can be represented in several different ways: an
array or vector of Boolean values, or any other scalar value that can
be assimilated to it, or as a bitstring using generally ``1'' for true
values or ``0'' for false values. Different data structures will have
an impact on the result, since the operations that are applied to them
are, in many cases, completely different and thus the underlying
implementation is more or less efficient. Besides, languages use
different native data structures to represent this information. In
general, it can be divided into three different fields:\begin{itemize}
\item {\em Strings}: representing a set bit by 1 and unset by 0, it is
  a data structure present in all languages and simple to use in
  most.
\item {\em Vector of Boolean values}: not all languages have a
  specific primitive type for the Boolean false and true values; for
  those who have, sometimes they have specific implementations that
  make this data structure the most efficient. In some and when they
  boolean values were not available, 1 or 0 were used. 
\item {\em Bitsets}: since the internal representation of any data
  structure is composed, at a low level, by a set of bits,  you can
  simply use bits packed 
  into bytes for representing chromosomes, with 32 bits packed in a
  single 4 byte data structure and bigger number of bytes used as
  needed.
\item {\em Lists} are accessed only sequentially, although running
  loops over them might be more efficient that using random-access
  methods such as the ones above.
\end{itemize}

Besides, many languages, including functional ones, differentiate
between Mutable and Constant data structures, with different internal
representations assigned to every one of them, and extensive
optimizations used in Immutable or constant data structures. Immutable
data structures are mainly used in functional languages, but some
scripting languages like Ruby or Python use it for strings too. 

In this paper around 30 languages, some of them with several implementations, have been chosen for performing all
benchmarks; additionally, another language, Rust, has been tested for
one of them and Clojure using persistent vectors was tested only for Onemax. This list includes 9 out of 10 languages from top 10 of the TIOBE
index \cite{tiobe16}, with Visual Basic the only one missing, and 1
more out of the top 20 (or two if we include Octave instead of the
proprietary application Matlab). The list of languages and alternative
implementations is shown in Table \ref{tab:files}. 

\begin{table*}[h!tb]
    \centering
    \begin{tabular}{l|c|l|l|l}
      \hline
      Language & Version & URL & Data structures & Type\\
      \hline
      C & 4.8.2 & \url{http://git.io/v8T57} & char vector & Compiled \\
      C++ & 4.8.4 & \url{http://git.io/v8T57} & bitset  & Compiled\\
      C\# & mono 4.2  & \url{https://git.io/vzHDI} & Bit Vector  & Compiled\\
      Clojure & 1.8.0 & \url{https://git.io/vzHDe} & Persistent Vector &  Compiled \\ 
      Common Lisp & 0.13.7 & \url{https://git.io/vzHyR} & Simple Bit Vector &  Compiled\\ 
      Go & go1.2.1 & \url{http://git.io/vBSYp} & Bit Vector & Compiled\\
      Haskell & ghc 7.10.3 & \url{https://git.io/vzHMw} & Mutable Vector & Compiled \\ 
      Java & 1.8.0\_66 & \url{http://git.io/v8TdR} & Bitset & Compiled\\
      JavaScript & node.js 5.0.0 & \url{http://git.io/vBSYd} & String & Interpreted\\
      Julia & 0.2.1 & \url{http://git.io/vBSOe} & Bit Vector & Interpreted \\
      Lua & 5.2.3 & \url{http://git.io/vBSY7} & String & Interpreted\\
      Octave & 3.8.1 & \url{http://git.io/v8T57} & BitVector & Interpreted \\ 
      PHP & 5.5.9 & \url{http://git.io/v8k9g} & String & Interpreted\\ % vrivas, 5-nov-2015
      Perl & v5.20.0 & \url{http://git.io/bperl} & String, Bit Vector & Interpreted \\
      Python & 2.7.3 & \url{http://git.io/vBSYb} & String & Interpreted\\
      Python 3 & 3.4.3 & \url{https://git.io/p3deap} & Bit Vector, List & Interpreted\\
      Rust &  1.4.0  & \url{https://github.com/JJ/RustEO} & Bit Vector  & Compiled \\ 
      Scala & 2.11.7 & \url{http://git.io/vBSYH} & String, Bit Vector & Compiled \\
      Ruby & 1.9.3p551 & \url{https://git.io/rEO} & Bit Vector & Interpreted \\
      JRuby & 9.0.5.0 (2.2.3) & \url{https://git.io/rEO} & Bit Vector & Interpreted \\
      Free Pascal & 2.6.2-8 & \url{https://git.io/fpeo} & Bit Vector & Compiled \\
      Kotlin & 1.0.1 & \url{https://git.io/kEO} & Bit Vector &  Compiled \\
      Dart & 1.15.0 & \url{https://git.io/dEO} & List & Interpreted \\ 
 
      \hline
      \end{tabular}
      \vspace{5mm}
      \caption{Languages, versions, URLs, data structure and type of
        language used to carry out the
        benchmarks. No special flags were used for the interpreter or
        compiler. \label{tab:files}}
    \end{table*}
%

When available, open source implementations of the operators and OneMax were used.
In all cases except in Scala, implementation took less than one hour and was
inspired by the initial implementation made in Perl or in Lua. In
fact, we abandoned languages such as AWK or FORTRAN when it took too
long to make a proper implementation in them.
Adequate data and control
structures were used for running the application, which applies
mutation to a single generated chromosome a hundred thousand
times. The length of the mutated string starts at 16 and is doubled
until reaching $2^{15}$, that is, 32768. This upper length was chosen to
have an ample range, but also so small as to be able to run the
benchmarks within one hour. Results are shown next. In some cases and
when the whole test took less than one hour, length was taken up to
$2^{16}$.

In most cases, and specially in the ones where no implementation was
readily available, we wrote small programs with very little overhead
that called the functions directly. That means that using classes,
function-call chains, and other artifacts, will add an overhead to the
benchmark; besides, this implies that the implementation is not
exactly the same for all languages. However, this inequality reflects
what would be available for anyone implementing an evolutionary
algorithm and, when we think it might have an influence on the final
result, we will note it. 

Every program used also provides native capabilities for measuring
time, using system calls to check the time before and after operations
were performed. These facilities used the maximum resolution
available, which in some cases, namely Pascal, was somewhat inadequate.

All programs produced the same output, a comma separated set of values
that includes the language and data structure used, operand length and
time in seconds. 

\section{Results and analysis}
\label{sec:res}

All the results have been made available in the repository that holds
this paper as well as some of the implementations, at
\url{https://git.io/bPPSN16}. Implementation and results are available
with a free license. The Linux system it has been tested is {\tt
  3.13.0-34-generic \#60-Ubuntu SMP} with an {\tt Intel(R) Core(TM)
  i7-4770 CPU @ 3.40GHz}. In this paper we will look mainly at the
aggregated results, comparing the differences in order of magnitude
between the different languages and also how they compare to each
other. 

\begin{figure}[h!tb]
  \centering
<<results-ratios,message=FALSE, cache=FALSE,echo=FALSE>>=
ggplot(ratios,aes(x=reorder(Language, -Ratio, FUN=median),Language,y=Ratio))+ geom_boxplot(notch=TRUE)+ theme(axis.text.x = element_text(angle = 90, hjust = 1))+scale_y_log10()+labs(x='Language')
@ 
\caption{Boxplot of scaled performance compared to baseline Julia. Please note
that $y$ has a logarithmic scale.}
\label{fig:ratios}
\end{figure}
%
To have a general idea of performance and be able to compare across
benchmarks and sizes, we have used the language Julia, whose
performance is more or less in the middle,  as a baseline for comparison
and expressed all times as the ratio between the time needed for a
particular language and length and the speed for Julia. Ratios higher than 1 mean that the particular language+data
structure is faster than Julia, $<$1 the opposite. Please check the
boxplot in Figure \ref{fig:ratios} for the average and standard
deviation across all functions and lengths, when the comparison is
possible. 

We should first refer to the remarkable performace of Clojure using
persistent vectors. Clojure is a functional language, and immutable
structures lend themselves better to functional processing. Clojure
includes some specific functions for this kind of counting. However,
it should be noted that the we could not run clojure on the rest of
the functions, bitflip and crossover. 

Next comes Java, with a performance that is around two orders of
magnitude better than baseline. In some cases, Clojure using mutable
vectors can be very fast too, but its overall performance takes it to
the third worst overall performance. This also implies that simply
choosing a language is not a guarantee of performance; data structures
chosen and implementation play also a major role. 

The top 5 is completed with C\#, Haskell and Scala, this last using
also a particular implementation, BitVector; if a more {\em natural}
BitString is used, its performance is on a par with the aforementioned
Clojure. Out of the top 5, three of them are functional languages:
Haskell, Clojure and Scala; clojure is also an interpreted language,
with a JIT compiler that targets the Java Virtual Machine. Three of
them also use the Java Virtual Machine: Clojure, Java and Scala; C\#
has its own runtime too, with Haskell having a compiler to native
object code, being thus the only {\em pure} compiled language in this
set. 

The biggest differences reside among the top 3 languages. Haskell,
Scala, Go, C and Perl have a very similar performance, and it should
be remarked that Perl is the first interpreted language in the
list. Other compiled languages, including C++, have worse performance,
and the worst 10 include several compiled languages, as well as
functional languages such as clisp. Also Perl in a different
implementation, showing once again that a particular language, by
itself, need not be a guarantee of performance. 

From the best to the worst implementation, there are 4 orders of
magnitude of difference. This can be quite important because the range
of running time between the slowest and the fastest can go from 1
second to several hours. Languages such as Octave or clisp, maybe even
Python and Julia, should be avoided except for problems with a size
that allows them to be run in a few seconds. 

However, let us rank the languages looking at how they fare, comparing
with the other implementations. 

\begin{figure}[h!tb]
  \centering
<<results-ranks,message=FALSE, cache=FALSE,echo=FALSE>>=
ggplot( ranks, aes(x=reorder(LanguageData,AvgRank), y=30-AvgRank))+ geom_bar(stat='identity',fill='orange',color='darkblue')+ theme_tufte() + theme(axis.text.x = element_text(angle = 90, hjust = 1))+labs(title='Average rank',x='Language+Data Structure',y='30-average rank')
@ 
\caption{Ranking averaged across all measures, substracted from the
  total number of measured languages, so bigger is better}
\label{fig:ranks}
\end{figure}

\section{Conclusions}

In this paper we have measured the performance of an extensive
collection of languages in simple and common evolutionary algorithm
operations: mutation, crossover and onemax with the objective of
finding out which languages are faster at these operations and what
are the actual differences across languages, language types and data
structures. 

We can conclude that the language usually considered the fastest among
the practitioners,
Java, indeed holds that position. However, compiled languages need not
be much faster than interpreted languages with Perl, for instance,
having a speed which is very close to C and Clojure, a scripting
language that compiles to the Java Virtual Machine, being faster than
both. But in this case it is using a particular data structure, and
our tests also show that data structures and code layout have to be
chosen carefully with performance in mind. An incorrect choice and the
performance advantage of fast languages such as Scala will disappear. 

Among interpreted languages Perl, node and PHP are the fastest, with
languages such as Octave or Python having lower performance that
should be expected. Haskell, on the other hand, is included among the
fastest, but it should be noted that in a particular case we 
could not perform the test due to excessive time, so this advantage
should extend only to particular lengths. 

All these tests lead us to the conclusion that there is no type of language
that is superior to all others across all chromosome sizes, problems and data
structures, although if you use Java with BitSets or C\# you will be
close to the best or reach the best running speed. There is no
free lunch also in the implementation in
EAs, and the fact that heterogeneous, asynchronous
distributed architectures are now possible leads us to propose them as
an alternative to the single-language frameworks that are the most
usual nowadays. 

Future lines of work might include a more extensive measurement of
other operators such as  tournament selection and other selection
algorithms. A priori, these are essentially CPU integer
operations and their behavior might be, in principle, very similar to 
the one shown in these operations. This remains to be proved, however, but it is left
as future line of work. It would also be interesting to mix and match
different languages, choosing every one for its performance, in a hybrid
architecture. Communication might have some overhead, but it might be
offset by performance. Combining some compiled languages such as Go or
C with others characterized by its speed in some string operations,
like Perl or programming ease, like Python, might result in the best of both worlds:
performance and rapid prototyping. Creating a whole multi-language
framework along these lines is a challenge that might be interesting
in the future.

Focusing only in the part of measuring algorithms and in the interest
of reproductibility, we intend to create
a virtual machine image with all the tests so that it can be downloaded and
run anywhere. A comprehensive repository with tests and comments will
also be a good forum where different languages and implementations can
be discussed.  


\section*{Acknowledgements}

This paper is part of the open science effort at the university of
Granada. It has been written using {\tt knitr}, and its source as well as
the data used to create it can be downloaded from 
\href{https://github.com/JJ/2016-ea-languages-wcci}{the GitHub
  repository} \url{https://github.com/JJ/2016-ea-languages-wcci/}. 
It has been supported in part by
\href{http://geneura.wordpress.com}{GeNeura Team}, 
projects TIN2014-56494-C4-3-P (Spanish Ministry of Economy and Competitiveness),
Conacyt Project PROINNOVA-220590,
PRY142/14 (Fundaci{\'o}n P{\'u}blica Andaluza Centro de Estudios Andaluces 
en la IX Convocatoria de Proyectos de Investigaci{\'o}n), 
PROY-PP2015-06 (Plan Propio 2015 UGR), 
and project V17-2015 of the Microprojects program 2015 from CEI BioTIC Granada.  


\bibliographystyle{IEEEtran}
\bibliography{geneura,languages,GA-general}
%\bibliography{languages}
\end{document}

%%% Local Variables:
%%% ispell-local-dictionary: "english"
%%% hunspell-local-dictionary: "english"
%%% End:
